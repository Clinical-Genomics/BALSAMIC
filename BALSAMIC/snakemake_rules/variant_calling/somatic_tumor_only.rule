# vim: syntax=python tabstop=4 expandtab
# coding: utf-8

import os

from BALSAMIC.utils.rule import get_picard_mrkdup
from BALSAMIC.utils.rule import get_conda_env
from BALSAMIC.utils.rule import get_chrom
from BALSAMIC.utils.rule import get_sample_type
from BALSAMIC.utils.rule import get_threads
from BALSAMIC import __version__ as bv

picarddup = get_picard_mrkdup(config)
chromlist = config["panel"]["chrom"]
capture_kit = os.path.split(config["panel"]["capture_kit"])[1]


def get_pon(config):
    """ return pon cli string, complete with file """
    if "PON" in config["analysis"]:
        return os.path.abspth(config["analysis"]["PON"])
    else:
        return None

rule vardict_tumor_only:
  input:
    fa = config["reference"]["reference_genome"],
    bamT = bam_dir + "tumor.merged.bam",
    bed = vcf_dir + "split_bed/{bedchrom}." + capture_kit,
  output:
    temp(vcf_dir + "vardict/split_vcf/{bedchrom}_vardict.vcf.gz")
  params:
    tmpdir = tmp_dir,
    af = "0.001",
    max_pval = "0.9",
    max_mm = "4.5",
    col_info = "-c 1 -S 2 -E 3 -g 4",
    name = config["analysis"]["case_id"],
    conda = get_conda_env(config["conda_env_yaml"],"vardict"),
  singularity: singularity_image
  benchmark:
    benchmark_dir + 'vardict_tumor_only_' + '{bedchrom}.vardict.tsv'
  shell:
    "source activate {params.conda}; "
    "export PERL5LIB=;"
    "rand_str=$(openssl rand -hex 5); "
    "tmpdir={params.tmpdir}/${{rand_str}}; "
    "mkdir -p ${{tmpdir}}; "
    "export TMPDIR=${{tmpdir}}; "
    "export VAR_DICT_OPTS='\"-Djava.io.tmpdir=${{tmpdir}}\" \"-Xms768m\" \"-Xmx8g\"'; "
    "vardict-java -u -I 600 -G {input.fa} -f {params.af} -N {params.name} "
        "-b {input.bamT} "
        "{params.col_info} {input.bed} "
        "| teststrandbias.R "
        "| var2vcf_valid.pl -P {params.max_pval} "
        "-m {params.max_mm} -E -f {params.af} -N {params.name} "
        "| bgzip > {output}; "
    "tabix -p vcf {output}; "
    "source deactivate;"

rule vardict_merge:
  input:
    expand(vcf_dir + "vardict/split_vcf/{chrom}_vardict.vcf.gz", chrom=chromlist)
  output:
    namemap = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".vardict.sample_name_map",
    yaml = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".vardict.yaml",
    vcf = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".vardict.vcf.gz"
  params:
    tmpdir = tmp_dir,
    conda = get_conda_env(config["conda_env_yaml"],"vardict"),
    name = config["analysis"]["case_id"],
  singularity: singularity_image
  benchmark:
    benchmark_dir + 'vardict_merge_' + config["analysis"]["case_id"] + ".vardict_merge.tsv"
  shell:
    "source activate {params.conda} ; "
    "rand_str=$(openssl rand -hex 5); "
    "tmpdir={params.tmpdir}/${{rand_str}}; "
    "mkdir -p ${{tmpdir}}; "
    "export TMPDIR=${{tmpdir}}; "
    "bcftools concat {input} | bcftools sort --temp-dir ${{tmpdir}} - | bgzip > {output.vcf}; "
    "tabix -f -p vcf {output.vcf}; "
    "echo -e \"{params.name}\\tTUMOR\" > {output.namemap}; " 
    "echo -e \"{params.name}\" > {output.namemap}.tumor; " 
    "echo '{{ vcf: {{ vardict: {{ name: vardict , path: {output.vcf} }} }} }}' > {output.yaml}; "
    "source deactivate;" 


rule mutect2_tumor_only:
  input:
    fa = config["reference"]["reference_genome"],
    dbsnp = config["reference"]["dbsnp"],
    cosmic = config["reference"]["cosmic"],
    bamT = bam_dir + "tumor.sorted." + picarddup + ".bsrcl.merged.bam",
    bed = vcf_dir + "split_bed/{bedchrom}." + capture_kit,
  output:
    temp(vcf_dir + "mutect/split_vcf/{bedchrom}_mutect.vcf.gz")
  params:
    tmpdir = tmp_dir,
    conda = get_conda_env(config["conda_env_yaml"],"gatk")
  threads: get_threads(cluster_config, "mutect2_tumor_only")
  singularity: singularity_image
  benchmark:
    benchmark_dir + 'mutect2_tumor_only_' + "{bedchrom}.mutect2_tumor_only.tsv"
  shell:
    "source activate {params.conda};"
    "rand_str=$(openssl rand -hex 5); "
    "tmpdir={params.tmpdir}/${{rand_str}}; "
    "mkdir -p ${{tmpdir}}; "
    "export TMPDIR=${{tmpdir}}; "
    "java -jar -Djava.io.tmpdir=${{tmpdir}} -Xms8G -Xmx32G $CONDA_PREFIX/opt/gatk-3.8/GenomeAnalysisTK.jar "
        "-T MuTect2 "
        "-R {input.fa} "
        "--cosmic {input.cosmic} "
        "--dbsnp {input.dbsnp} "
        "-I:tumor {input.bamT} "
        "--useNewAFCalculator "
        "--disable_auto_index_creation_and_locking_when_reading_rods "
        "-L {input.bed} "
    " | bgzip > {output}; "
    "tabix -p vcf {output}; " 
    

rule mutect2_merge: 
  input:  
    expand(vcf_dir + "mutect/split_vcf/{chrom}_mutect.vcf.gz", chrom=chromlist)   
  output: 
    namemap = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".mutect.sample_name_map",
    yaml = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".mutect.yaml",
    vcf = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".mutect.vcf.gz"  
  params: 
    tmpdir = tmp_dir, 
    conda = get_conda_env(config["conda_env_yaml"],"bcftools"),
  singularity: singularity_image
  benchmark:
    benchmark_dir + 'mutect2_merge_' + config["analysis"]["case_id"] + ".mutect2_merge.tsv"
  shell:  
    "source activate {params.conda} ; " 
    "rand_str=$(openssl rand -hex 5); "
    "tmpdir={params.tmpdir}/${{rand_str}}; "
    "mkdir -p ${{tmpdir}}; "
    "export TMPDIR=${{tmpdir}}; "
    "bcftools concat {input} | bcftools sort --temp-dir ${{tmpdir}} - | bgzip > {output.vcf}; "  
    "tabix -f -p vcf {output.vcf}; "  
    "echo -e \"TUMOR\\tTUMOR\" > {output.namemap}; " 
    "echo -e \"TUMOR\" > {output.namemap}.tumor; " 
    "echo '{{ vcf: {{ mutect: {{ name: mutect2 , path: {output.vcf} }} }} }}' > {output.yaml}; "
    "source deactivate;" 


rule somatic_snv_indel_vcf_merge:
    input:
        name_map = expand(vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".{var_caller}.sample_name_map", var_caller=somatic_caller_snv),
        varcall_yaml = expand(vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".{var_caller}.yaml", var_caller=somatic_caller_snv),
        refdict = (config["reference"]["reference_genome"]).replace(".fasta",".dict"),
        reffasta = config["reference"]["reference_genome"],
        bamT = bam_dir + "tumor.merged.bam",
    output:
        vcfmerge = vcf_dir + "vcfmerge/SNV.somatic." + config["analysis"]["case_id"] + ".vcfmerge.vcf.gz",
        vcf = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".vcfmerge.vcf.gz"
    params:
        workdir = vcf_dir + "/vcfmerge",
        conda = get_conda_env(config["conda_env_yaml"],"vcfmerge")
    threads: get_threads(cluster_config, 'somatic_snv_indel_vcf_merge')
    singularity: singularity_image 
    benchmark:
        benchmark_dir + "somatic_snv_inde_vcf_merge.tsv"
    shell:
        "source activate {params.conda}; "
        "mkdir -p {params.workdir}; "
        "cat {input.name_map} > {params.workdir}/sample_name.map; "
        "echo '{{bam: {{TUMOR: {input.bamT} }} }}' | "
          " yq -s '{{ vcf: map(.vcf) | add }} * .[0]'  - {input.varcall_yaml} "
          " > {params.workdir}/vcf.yaml; "
        "vcfmerge --sample-config {params.workdir}/vcf.yaml "
          " --reference-dict {input.refdict} "
          " --reference {input.reffasta} "
          " --sample-names {params.workdir}/sample_name.map "
          " --aggr-func max "
          " --output-dir {params.workdir} "
          " --mapq 10 "
          " --include-optional "
          " --output-vcf {output.vcf}; " 
        "cp {output.vcfmerge} {output.vcf}; "
        


rule sentieon_TNhaplotyper_tumor_only:
    input:
        bam = bam_dir + "tumor.sorted." + picarddup + ".bsrcl.merged.bam",
        ref = config["reference"]["reference_genome"],
        dbsnp = config["reference"]["dbsnp"],
        cosmic = config["reference"]["cosmic"],
        interval = config["panel"]["capture_kit"],
    output:
        vcf = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".tnhaplotyper.vcf.gz",
        namemap = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".tnhaplotyper.sample_name_map",
    params:
        tmpdir = tmp_dir, 
        tumor = get_sample_type(config["samples"], "tumor"),
        pon = " " if get_pon(config) is None else " ".join(["--pon", get_pon(config)]), 
        sentieon_exec = config["SENTIEON_INSTALL_DIR"] + "/bin/sentieon",
        sentieon_lic = config["SENTIEON_LICENSE"],
    threads: get_threads(cluster_config, 'sentieon_TNhaplotyper_tumor_only')
    log:
        vcf_dir + config["analysis"]["case_id"] + ".tnsnv.log"
    benchmark:
        benchmark_dir + 'sentieon_TNhaplotyper_tumor_only_' + config["analysis"]["case_id"] + ".tnhaplotyper.tsv"
    shell:
        """
rand_str=$(openssl rand -hex 5);
tmpdir={params.tmpdir}/${{rand_str}}; 
mkdir -p ${{tmpdir}}; 
export TMPDIR=${{tmpdir}}; 
export SENTIEON_TMPDIR=${{tmpdir}};
export SENTIEON_LICENSE={params.sentieon_lic};

{params.sentieon_exec} driver -r {input.ref} -t {threads} -i {input.bam} --interval {input.interval} --algo TNhaplotyper --tumor_sample TUMOR {params.pon} --cosmic {input.cosmic} --dbsnp {input.dbsnp} {output.vcf} 

echo -e \"TUMOR\\tTUMOR\" > {output.namemap};
        """
