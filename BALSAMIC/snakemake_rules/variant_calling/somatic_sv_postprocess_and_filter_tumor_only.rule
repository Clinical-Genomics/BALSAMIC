
rule bcftools_process_SV_CNV:
    input:
        delly_sv = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".delly.bcf",
        delly_cnv = vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".delly.bcf",
    output:
        delly_sv = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".dellysv.vcf.gz",
        cnv = temp(vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".tmpdellyCNV.vcf.gz"),
        delly_cnv= vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".dellycnv.vcf.gz",
    benchmark:
        Path(benchmark_dir, 'bcftools_process_SV_CNV_' + config["analysis"]["case_id"] + ".tsv")
    singularity:
        Path(singularity_image, config["bioinfo_tools"].get("bcftools") + ".sif").as_posix()
    params:
        case_name = config["analysis"]["case_id"],
        process_cnv = get_script_path("process_CNV.py"),
    threads:
        get_threads(cluster_config, "bcftools_process_SV_CNV")
    message:
        ("Converting BCF from delly to VCF for {params.case_name}")
    shell:
        """
    bcftools view  --threads {threads} -f PASS -O z -o {output.delly_sv} {input.delly_sv};
    
    bcftools view --threads {threads} -f PASS -O z -o {output.cnv} {input.delly_cnv};
    
    python {params.process_cnv} -f {output.cnv} -c delly | bgzip -l 9 -c > {output.delly_cnv};
    
    tabix -p vcf -f {output.delly_sv};
    
    tabix -p vcf -f {output.delly_cnv};
        """

rule svdb_merge_tumor_only:
    input:
        vcf = expand(
                vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".{caller}.vcf.gz",
                caller=somatic_caller_sv) +
              expand(
                vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".{caller}.vcf.gz",
                caller=somatic_caller_cnv)
    output:
        vcf_svdb = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".svdb.vcf.gz",
        namemap = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".svdb.sample_name_map",
    benchmark:
        Path(benchmark_dir, 'svdb_merge_tumor_only_' + config["analysis"]["case_id"] + ".tsv")
    singularity:
        Path(singularity_image, config["bioinfo_tools"].get("svdb") + ".sif").as_posix()
    params:
        housekeeper_id = {"id": config["analysis"]["case_id"], "tags": "research"},
        tumor = config_model.get_sample_name_by_type(SampleType.TUMOR),
        case_name = config["analysis"]["case_id"],
        vcf= lambda wildcards, input:[input[index] + ":" + svdb_callers_prio[index] for index in range(0,len(input))],
        svdb_priority= ",".join(svdb_callers_prio)
    threads:
        get_threads(cluster_config, "svdb_merge_tumor_only")
    message:
        "Merging structural and copy number variants using SVDB for {params.case_name}"
    shell:
        """
    svdb --merge --no_intra --bnd_distance 5000 --overlap 0.80 \
    --vcf {params.vcf} \
    --priority {params.svdb_priority} | \
    bgzip -l 9 -c > {output.vcf_svdb};
    tabix -p vcf -f {output.vcf_svdb};
    
    echo -e \"{params.tumor}\\tTUMOR\" > {output.namemap};
        """

rule bcftools_quality_filter_svdb:
    input:
        vcf_svdb = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".svdb.vcf.gz",
    output:
        vcf_pass_svdb_research = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".svdb.research.vcf.gz",
    benchmark:
        Path(benchmark_dir, 'bcftools_quality_filter_sv_' + config["analysis"]["case_id"] + ".tsv")
    singularity:
        Path(singularity_image,config["bioinfo_tools"].get("bcftools") + ".sif").as_posix()
    params:
        case_name = config["analysis"]["case_id"],
    threads:
        get_threads(cluster_config, "bcftools_quality_filter_svdb")
    message:
        "Filtering merged research structural and copy number variants using bcftools for {params.case_name}"
    shell:
        """
    bcftools view --threads {threads} -f .,PASS -o {output.vcf_pass_svdb_research} -O z {input.vcf_svdb};
    
    tabix -p vcf -f {output.vcf_pass_svdb_research};
        """