if config["analysis"]["sequencing_type"] == 'wgs':
  rule bcftools_process_SV_CNV:
      input:
          delly_sv=vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".delly.bcf",
          delly_cnv=vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".delly.bcf",
          ascat_cnv=vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".raw.ascat.vcf.gz",
      output:
          delly_sv=vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".dellysv.vcf.gz",
          tmp_delly_cnv=temp(vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".tmpdellyCNV.vcf.gz"),
          delly_cnv=vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".dellycnv.vcf.gz",
          ascat_cnv=vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".ascat.vcf.gz",
      benchmark:
          Path(benchmark_dir,'bcftools_process_SV_CNV_' + config["analysis"]["case_id"] + ".tsv")
      singularity:
          Path(singularity_image,config["bioinfo_tools"].get("bcftools") + ".sif").as_posix()
      params:
          case_name=config["analysis"]["case_id"],
          process_cnv=get_script_path("process_CNV.py"),
      threads:
          get_threads(cluster_config,"bcftools_process_SV_CNV")
      message:
          ("Processing SVs and CNVs for {params.case_name}")
      shell:
        """
  bcftools view  --threads {threads} -f PASS -O z -o {output.delly_sv} {input.delly_sv};
  
  bcftools view --threads {threads} -f PASS -O z -o {output.tmp_delly_cnv} {input.delly_cnv};
  
  python {params.process_cnv} -f {output.tmp_delly_cnv} -c delly | bgzip -l 9 -c > {output.delly_cnv};
  
  python {params.process_cnv} -f {input.ascat_cnv} -c ascat | bgzip -l 9 -c > {output.ascat_cnv};
  
  tabix -p vcf -f {output.delly_sv};
  
  tabix -p vcf -f {output.delly_cnv};
  
  tabix -p vcf -f {output.ascat_cnv};
  
  rm {input.ascat_cnv};
        """
else:
  rule bcftools_process_SV_CNV:
      input:
          delly_sv = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".delly.bcf",
          delly_cnv = vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".delly.bcf",
      output:
          delly_sv = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".dellysv.vcf.gz",
          tmp_delly_cnv = temp(vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".tmpdellyCNV.vcf.gz"),
          delly_cnv= vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".dellycnv.vcf.gz",
      benchmark:
          Path(benchmark_dir, 'bcftools_process_SV_CNV_' + config["analysis"]["case_id"] + ".tsv")
      singularity:
          Path(singularity_image, config["bioinfo_tools"].get("bcftools") + ".sif").as_posix()
      params:
          case_name = config["analysis"]["case_id"],
          process_cnv = get_script_path("process_CNV.py"),
      threads:
          get_threads(cluster_config, "bcftools_process_SV_CNV")
      message:
          ("Processing SVs and CNVs for {params.case_name}")
      shell:
        """
  bcftools view  --threads {threads} -f PASS -O z -o {output.delly_sv} {input.delly_sv};
    
  bcftools view --threads {threads} -f PASS -O z -o {output.tmp_delly_cnv} {input.delly_cnv};
    
  python {params.process_cnv} -f {output.tmp_delly_cnv} -c delly | bgzip -l 9 -c > {output.delly_cnv};
    
  tabix -p vcf -f {output.delly_sv};
    
  tabix -p vcf -f {output.delly_cnv};
        """

rule svdb_merge_tumor_normal:
    input:
        vcf = expand(
                vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".{caller}.vcf.gz",
                caller=somatic_caller_sv) +
              expand(
                vcf_dir + "CNV.somatic." + config["analysis"]["case_id"] + ".{caller}.vcf.gz",
                caller=somatic_caller_cnv)
    output:
        vcf_svdb = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".svdb.vcf.gz",
        namemap = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".svdb.sample_name_map",
    benchmark:
        Path(benchmark_dir, 'svdb_merge_tumor_normal_' + config["analysis"]["case_id"] + ".tsv")
    singularity:
        Path(singularity_image, config["bioinfo_tools"].get("svdb") + ".sif").as_posix()
    params:
        housekeeper_id = {"id": config["analysis"]["case_id"], "tags": "research"},
        tumor = config_model.get_sample_name_by_type(SampleType.TUMOR),
        normal = config_model.get_sample_name_by_type(SampleType.NORMAL),
        case_name = config["analysis"]["case_id"],
        vcf= lambda wildcards, input:[input[index] + ":" + svdb_callers_prio[index] for index in range(0,len(input))],
        svdb_priority= ",".join(svdb_callers_prio)
    threads:
        get_threads(cluster_config, "svdb_merge_tumor_normal")
    message:
        "Merging structural and copy number variants using SVDB for {params.case_name}"
    shell:
        """
  svdb --merge --no_intra --bnd_distance 5000 --overlap 0.80 \
  --vcf {params.vcf} \
  --priority {params.svdb_priority} | \
  bgzip -l 9 -c  > {output.vcf_svdb};
  tabix -p vcf -f {output.vcf_svdb};
  
  echo -e \"{params.tumor}\\tTUMOR\\n{params.normal}\\tNORMAL\" > {output.namemap};
        """

rule bcftools_quality_filter_svdb:
    input:
        vcf_svdb = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".svdb.vcf.gz",
    output:
        vcf_pass_svdb_research = vcf_dir + "SV.somatic." + config["analysis"]["case_id"] + ".svdb.research.vcf.gz",
    benchmark:
        Path(benchmark_dir, 'bcftools_quality_filter_sv_' + config["analysis"]["case_id"] + ".tsv")
    singularity:
        Path(singularity_image,config["bioinfo_tools"].get("bcftools") + ".sif").as_posix()
    params:
        case_name = config["analysis"]["case_id"],
    threads:
        get_threads(cluster_config, "bcftools_quality_filter_svdb")
    message:
        "Filtering merged research structural and copy number variants using bcftools for {params.case_name}"
    shell:
      """
  bcftools view --threads {threads} -f .,PASS -o {output.vcf_pass_svdb_research} -O z {input.vcf_svdb};
  
  tabix -p vcf -f {output.vcf_pass_svdb_research};
      """
