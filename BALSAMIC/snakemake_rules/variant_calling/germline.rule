# vim: syntax=python tabstop=4 expandtab
# coding: utf-8

__author__ = "Hassan Foroughi Asl"

import os
from BALSAMIC.utils.rule import get_conda_env
from BALSAMIC.utils.rule import get_picard_mrkdup
from BALSAMIC.utils.rule import get_threads
from BALSAMIC import __version__ as bv


chromlist = config["panel"]["chrom"]
picarddup = get_picard_mrkdup(config)
capture_kit = os.path.split(config["panel"]["capture_kit"])[1]

rule haplotypecaller:
    input:
        fa = config["reference"]["reference_genome"],
        bam = bam_dir + "{sample}.sorted." + picarddup  + ".bam",
        bed = vcf_dir + "split_bed/{bedchrom}." + capture_kit,
    output:
        vcf_dir + "haplotypecaller/split_vcf/{sample}.{bedchrom}_haplotypecaller.vcf.gz"
    params:
        tmpdir = vcf_dir,
        conda = get_conda_env(config["conda_env_yaml"],"gatk"),
    threads: get_threads(cluster_config, 'haplotypecaller')
    singularity: singularity_image
    benchmark:
        benchmark_dir + 'haplotypecaller_' + "{sample}.{bedchrom}.haplotypecaller.tsv"
    shell:
        "source activate {params.conda};"
        "rand_str=$(openssl rand -hex 5); "
        "java -jar -Djava.io.tmpdir={params.tmpdir}/${{rand_str}} -Xms8G -Xmx32G $CONDA_PREFIX/opt/gatk-3.8/GenomeAnalysisTK.jar "
            "-T HaplotypeCaller "
            "-R {input.fa} "
            "-I {input.bam} "
            "-L {input.bed} "
            "| bgzip > {output}; " 
        


rule haplotypecaller_merge:
    input:
        expand(vcf_dir + "haplotypecaller/split_vcf/{{sample}}.{chrom}_haplotypecaller.vcf.gz", chrom=chromlist)
    output:
        vcf_dir + "SNV.germline.{sample}.haplotypecaller.vcf.gz"
    params:
        tmpdir = vcf_dir,
        conda = get_conda_env(config["conda_env_yaml"], "gatk"),
    singularity: singularity_image
    benchmark:
        benchmark_dir + 'haplotypecaller_merge_' + "SNV.germline.{sample}.haplotypecaller.vcf.gz" 
    shell:
        "source activate {params.conda}; "
        "rand_str=$(openssl rand -hex 5); "
        "bcftools concat {input} | bcftools sort --temp-dir {params.tmpdir}/${{rand_str}} - | bgzip > {output}; "
        "tabix -f -p vcf {output}; "


rule strelka_germline:
    input:
        fa = config["reference"]["reference_genome"],
        bam = bam_dir + "{sample}.sorted." + picarddup  + ".bam",
        mantaindel = vcf_dir + "manta_germline_{sample}/results/variants/candidateSmallIndels.vcf.gz"
    output:
        final = vcf_dir + "SNV.germline.{sample}.strelka_germline.vcf.gz"
    params:
        tmpdir = vcf_dir + "strelka_germline_{sample}/",
        runmode = "local",
        conda = get_conda_env(config["conda_env_yaml"],"strelka"),
    threads: get_threads(cluster_config, "strelka_germline")
    singularity: singularity_image
    benchmark:
        benchmark_dir + 'strelka_germline_' + "{sample}.strelka_germline.tsv"
    shell:
        "source activate {params.conda};"
        "rm -rf {params.tmpdir}; "
        "configureStrelkaGermlineWorkflow.py "
            "--bam={input.bam} "
            "--referenceFasta={input.fa} "
            "--indelCandidates {input.mantaindel} "
            "--exome "
            "--runDir={params.tmpdir}; "
        "python {params.tmpdir}/runWorkflow.py -m {params.runmode} -j {threads}; "
        "cp {params.tmpdir}/results/variants/variants.vcf.gz {output.final}; " 
        "tabix -p vcf -f {output.final}; "
        


rule manta_germline:
    input:
        fa = config["reference"]["reference_genome"],
        bam = bam_dir + "{sample}.sorted." + picarddup  + ".bam",
    output:
        final = vcf_dir + "SV.germline.{sample}.manta_germline.vcf.gz",
        candidateindel = vcf_dir + "manta_germline_{sample}/results/variants/candidateSmallIndels.vcf.gz" 
    params:
        tmpdir = vcf_dir + "manta_germline_{sample}/",
        runmode = "local",
        conda = get_conda_env(config["conda_env_yaml"],"manta"),
    threads: get_threads(cluster_config, "manta_germline")
    singularity: singularity_image
    benchmark:
        benchmark_dir + 'manta_germline_' + "{sample}.manta_germline.tsv"
    shell:
        "source activate {params.conda}; "
        "rm -rf {params.tmpdir}; "
        "configManta.py "
            "--bam={input.bam} "
            "--referenceFasta={input.fa} "
            "--runDir={params.tmpdir}; "
        "python {params.tmpdir}/runWorkflow.py -m {params.runmode} -j {threads}; "
        "cp {params.tmpdir}/results/variants/diploidSV.vcf.gz {output.final}; "
        "tabix -p vcf -f {output.final}; "
        


rule sentieon_DNAscope:
    input:
        bam = bam_dir + "{sample}.sorted." + picarddup + ".bam",
        ref = config["reference"]["reference_genome"],
        dbsnp = config["reference"]["dbsnp"],
        interval = config["panel"]["capture_kit"]
    output:
        vcf = vcf_dir + "SNV.germline.{sample}.dnascope.vcf.gz",
    params:
        tmpdir = vcf_dir,
        sentieon_exec = SENTIEON_INSTALL_DIR + "/bin/sentieon",
        sentieon_lic = SENTIEON_LICENSE
    threads: get_threads(cluster_config, 'sentieon_DNAscope')
    log: 
        vcf_dir + "{sample}.dnascope.log"
    benchmark:
        benchmark_dir + "{sample}.dnascope.tsv"
    shell:
        """
export SENTIEON_LICENSE={params.sentieon_lic};

rand_str=$(openssl rand -hex 5); 
export SENTIEON_TMPDIR={params.tmpdir}/${{rand_str}}

{params.sentieon_exec} driver -t {threads} -r {input.ref} -i {input.bam} --interval {input.interval} --algo DNAscope -d {input.dbsnp} {output.vcf}
        """
