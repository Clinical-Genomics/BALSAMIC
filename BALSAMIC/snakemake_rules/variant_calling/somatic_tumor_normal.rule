# vim: syntax=python tabstop=4 expandtab
# coding: utf-8

import os
from BALSAMIC.utils.rule import get_picard_mrkdup
from BALSAMIC.utils.rule import get_conda_env
from BALSAMIC.utils.rule import get_chrom
from BALSAMIC.utils.rule import get_sample_type
from BALSAMIC.utils.rule import get_threads
from BALSAMIC import __version__ as bv

picarddup = get_picard_mrkdup(config)
chromlist = config["panel"]["chrom"]
capture_kit = os.path.split(config["panel"]["capture_kit"])[1]

rule vardict_tumor_normal:
  input:
    fa = config["reference"]["reference_genome"],
    bamN = bam_dir + "normal.merged.bam", 
    bamT = bam_dir + "tumor.merged.bam",
    bed = vcf_dir + "split_bed/{bedchrom}." + capture_kit,
  output:
    temp(vcf_dir + "vardict/split_vcf/{bedchrom}_vardict.vcf.gz")
  params:
    tmpdir = os.path.abspath(vcf_dir),
    af = "0.005",
    max_pval = "0.9",
    max_mm = "4.5",
    col_info = "-c 1 -S 2 -E 3 -g 4",
    name = config["analysis"]["case_id"],
    conda = get_conda_env(config["conda_env_yaml"], "vardict"),
  singularity: singularity_image
  benchmark:
    benchmark_dir + 'vardict_tumor_normal_' + "{bedchrom}.vardict_tumor_normal.tsv"
  shell:
    "source activate {params.conda}; "
    "export PERL5LIB=;"
    "rand_str=$(openssl rand -hex 5); "
    "mkdir {params.tmpdir}/${{rand_str}}; "
    "export TMPDIR={params.tmpdir}/${{rand_str}}; "
    "export VAR_DICT_OPTS='\"-Djava.io.tmpdir={params.tmpdir}/${{rand_str}}\" \"-Xms768m\" \"-Xmx8g\"'; "
    "vardict-java -U -u -I 600 -G {input.fa} -f {params.af} -N {params.name} "
        "-b \"{input.bamT}|{input.bamN}\" "
        "{params.col_info} {input.bed} "
        "| testsomatic.R "
        "| var2vcf_paired.pl -P {params.max_pval} "
        "-m {params.max_mm} -M -f {params.af} -N {params.name} "
        "| bgzip > {output}; "
    "tabix -p vcf {output}; "
    "source deactivate;"

rule vardict_merge:
  input:
    expand(vcf_dir + "vardict/split_vcf/{chrom}_vardict.vcf.gz", chrom=chromlist) 
  output:
    vcf = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".vardict.vcf.gz",
    yaml = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".vardict.yaml",
    namemap = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".vardict.sample_name_map"
  params:
    tmpdir = vcf_dir,
    conda = get_conda_env(config["conda_env_yaml"], "vardict"),
    name = config["analysis"]["case_id"],
  singularity: singularity_image
  benchmark:
    benchmark_dir + 'vardict_merge_' + config["analysis"]["case_id"] + ".vardict_merge.tsv"
  shell:
    "source activate {params.conda} ; "
    "rand_str=$(openssl rand -hex 5); "
    "bcftools concat {input} | bcftools sort --temp-dir {params.tmpdir}/${{rand_str}} - | bgzip > {output.vcf}; " 
    "tabix -f -p vcf {output.vcf}; "
    "echo -e \"{params.name}\\tTUMOR\n{params.name}-match\\tNORMAL\" > {output.namemap}; " 
    "echo -e \"{params.name}\" > {output.namemap}.tumor; " 
    "echo -e \"{params.name}-match\" > {output.namemap}.normal; " 
    "echo '{{ vcf: {{ vardict: {{ name: vardict, path: {output.vcf} }} }} }}' > {output.yaml}; "
    "source deactivate;" 


rule mutect2_tumor_normal:
  input:
    fa = config["reference"]["reference_genome"],
    dbsnp = config["reference"]["dbsnp"],
    cosmic = config["reference"]["cosmic"],
    bamT = bam_dir + "tumor.sorted." + picarddup + ".ralgn.bsrcl.merged.bam",
    bamN = bam_dir + "normal.sorted." + picarddup + ".ralgn.bsrcl.merged.bam",
    bed = vcf_dir + "split_bed/{bedchrom}." + capture_kit,
  output:
    temp(vcf_dir + "mutect/split_vcf/{bedchrom}_mutect.vcf.gz")
  params:
    tmpdir = vcf_dir + "mutect/",
    result_dir = vcf_dir + "mutect/",
    conda = get_conda_env(config["conda_env_yaml"],"gatk")
  threads: get_threads(cluster_config, "mutect2_tumor_normal")
  singularity: singularity_image
  benchmark:
    benchmark_dir + 'mutect2_tumor_normal_' + "{bedchrom}.mutect2_tumor_normal.tsv"
  shell:
    "source activate {params.conda};"
    "mkdir -p {params.result_dir}; "
    "rand_str=$(openssl rand -hex 5); "
    "java -jar -Djava.io.tmpdir={params.tmpdir}/${{rand_str}} -Xms8G -Xmx32G $CONDA_PREFIX/opt/gatk-3.8/GenomeAnalysisTK.jar "
        "-T MuTect2 "
        "-R {input.fa} "
        "--cosmic {input.cosmic} "
        "--dbsnp {input.dbsnp} "
        "-I:normal {input.bamN} "
        "-I:tumor {input.bamT} "
        "--useNewAFCalculator "
        "--disable_auto_index_creation_and_locking_when_reading_rods "
        "-L {input.bed} "
    " | bgzip > {output}; "
    "tabix -p vcf {output}; " 
    

rule mutect2_merge:
  input:
    expand(vcf_dir + "mutect/split_vcf/{chrom}_mutect.vcf.gz", chrom=chromlist) 
  output:
    namemap = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".mutect.sample_name_map",
    yaml = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".mutect.yaml",
    vcf = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".mutect.vcf.gz"
  params:
    tmpdir = vcf_dir,
    name = config["analysis"]["case_id"],
    conda = get_conda_env(config["conda_env_yaml"],"bcftools"),
  singularity: singularity_image
  benchmark:
    benchmark_dir + 'mutect2_merge_' + config["analysis"]["case_id"] + ".mutect2_merge.tsv"
  shell:
    "source activate {params.conda} ; "
    "rand_str=$(openssl rand -hex 5); "
    "bcftools concat {input} | bcftools sort --temp-dir {params.tmpdir}/${{rand_str}} - | bgzip > {output.vcf}; "
    "tabix -f -p vcf {output.vcf}; "
    "echo -e \"TUMOR\\tTUMOR\nNORMAL\\tNORMAL\" > {output.namemap}; " 
    "echo -e \"TUMOR\" > {output.namemap}.tumor; " 
    "echo -e \"NORMAL\" > {output.namemap}.normal; " 
    "echo '{{ vcf: {{ mutect: {{ name: mutect2, path: {output.vcf} }} }} }}' > {output.yaml}; "
    "source deactivate;" 

rule strelka_tumor_normal:
  input:
    fa = config["reference"]["reference_genome"],
    bamN = bam_dir + "normal.merged.bam", 
    bamT = bam_dir + "tumor.merged.bam",
    mantaindel = vcf_dir + "manta/results/variants/candidateSmallIndels.vcf.gz" 
  output:
    namemap = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".strelka.sample_name_map",
    yaml = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".strelka.yaml",
    final = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".strelka.vcf.gz", 
    default = expand(vcf_dir + "strelka/results/variants/{vcf_file}", vcf_file=["somatic.snvs.vcf.gz", "somatic.indels.vcf.gz"])
  params:
    name = config["analysis"]["case_id"],
    tmpdir = vcf_dir + "strelka/", 
    runmode = "local",
    conda = get_conda_env(config["conda_env_yaml"],"strelka"),
  threads: get_threads(cluster_config, "strelka_tumor_normal")
  singularity: singularity_image
  benchmark:
    benchmark_dir + 'strelka_tumor_normal_' + config["analysis"]["case_id"] + ".strelka_tumor_normal.tsv"
  shell:
    "source activate {params.conda};"
    "rm -rf {params.tmpdir}; "
    "configureStrelkaSomaticWorkflow.py "
        "--normalBam={input.bamN} "
        "--tumorBam={input.bamT} "
        "--referenceFasta={input.fa} "
        "--indelCandidates {input.mantaindel} "
        "--outputCallableRegions "
        "--exome "
        "--runDir={params.tmpdir}; "
    "python {params.tmpdir}/runWorkflow.py -m {params.runmode} -j {threads}; "
    "bcftools concat -a "
        "-o {output.final} "
        "-O z "
        "{output.default}; "
    "tabix -f -p vcf {output.final}; "
    "echo -e \"TUMOR\\tTUMOR\nNORMAL\\tNORMAL\" > {output.namemap}; " 
    "echo -e \"TUMOR\" > {output.namemap}.tumor; " 
    "echo -e \"NORMAL\" > {output.namemap}.normal; " 
    "echo '{{ vcf: {{ strelka: {{ name: strelka , path: {output.final} }} }} }}' > {output.yaml}; "
    


rule somatic_snv_indel_vcf_merge:
    input:
        name_map = expand(vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".{var_caller}.sample_name_map", var_caller=somatic_caller_snv),
        varcall_yaml = expand(vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".{var_caller}.yaml", var_caller=somatic_caller_snv),
        refdict = (config["reference"]["reference_genome"]).replace(".fasta",".dict"),
        reffasta = config["reference"]["reference_genome"],
        bamN = bam_dir + "normal.merged.bam", 
        bamT = bam_dir + "tumor.merged.bam",
    output:
        vcfmerge = vcf_dir + "vcfmerge/SNV.somatic." + config["analysis"]["case_id"] + ".vcfmerge.vcf.gz",
        vcf = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".vcfmerge.vcf.gz"
    params:
        workdir = vcf_dir + "/vcfmerge",
        conda = get_conda_env(config["conda_env_yaml"],"vcfmerge"),
    threads: get_threads(cluster_config, 'somatic_snv_indel_vcf_merge')
    singularity: singularity_image 
    benchmark:
        benchmark_dir + "somatic_snv_inde_vcf_merge.tsv"
    shell:
        "source activate {params.conda}; "
        "mkdir -p {params.workdir}; "
        "cat {input.name_map} > {params.workdir}/sample_name.map; "
        "echo '{{bam: {{NORMAL: {input.bamN}, TUMOR: {input.bamT} }} }}' | "
          " yq -s '{{ vcf: map(.vcf) | add }} * .[0]'  - {input.varcall_yaml} "
          " > {params.workdir}/vcf.yaml; "
        "vcfmerge --sample-config {params.workdir}/vcf.yaml "
          " --reference-dict {input.refdict} "
          " --reference {input.reffasta} "
          " --sample-names {params.workdir}/sample_name.map "
          " --aggr-func max "
          " --output-dir {params.workdir} "
          " --mapq 10 "
          " --include-optional "
          " --output-vcf {output.vcfmerge}; " 
        "cp {output.vcfmerge} {output.vcf}; "
        


rule sentieon_TNhaplotyper:
    input:
        bamT = bam_dir + "tumor.sorted." + picarddup + ".ralgn.bsrcl.merged.bam",
        bamN = bam_dir + "normal.sorted." + picarddup + ".ralgn.bsrcl.merged.bam",
        interval = config["panel"]["capture_kit"],
        ref = config["reference"]["reference_genome"],
        dbsnp = config["reference"]["dbsnp"],
    output:
        vcf = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".tnhaplotyper.vcf.gz",
        namemap = vcf_dir + "SNV.somatic." + config["analysis"]["case_id"] + ".tnhaplotyper.sample_name_map",
    params:
        tmpdir = os.path.abspath(vcf_dir),
        tumor = get_sample_type(config["samples"], "tumor"),
        normal = get_sample_type(config["samples"], "normal"),
        sentieon_exec = SENTIEON_INSTALL_DIR + "/bin/sentieon",
        sentieon_lic = SENTIEON_LICENSE, 
    threads: get_threads(cluster_config, 'sentieon_TNhaplotyper')
    log:
        vcf_dir + config["analysis"]["case_id"] + ".tnhaplotyper.log"
    benchmark:
        benchmark_dir + 'sentieon_TNhaplotyper_' + config["analysis"]["case_id"] + ".tnhaplotyper.tsv"
    shell:
        """
rand_str=$(openssl rand -hex 5);
mkdir {params.tmpdir}/${{rand_str}};
export SENTIEON_TMPDIR={params.tmpdir}/${{rand_str}};
export SENTIEON_LICENSE={params.sentieon_lic};

{params.sentieon_exec} driver -r {input.ref} -t {threads} -i {input.bamT} -i {input.bamN} --interval {input.interval} --algo TNhaplotyper --tumor_sample TUMOR --normal_sample NORMAL --dbsnp {input.dbsnp} {output.vcf}
        
echo -e \"TUMOR\\tTUMOR\nNORMAL\\tNORMAL\" > {output.namemap}; 
        """
