# vim: syntax=python tabstop=4 expandtab
# coding: utf-8

import os

from yapf.yapflib.yapf_api import FormatFile

from BALSAMIC.utils.cli import write_json
from BALSAMIC.utils.rule import get_result_dir
from BALSAMIC.utils.rule import get_vcf
from BALSAMIC import __version__ as bv

shell.prefix("set -eo pipefail; ")

rule_dir = config["rule_directory"]
benchmark_dir = config["analysis"]["benchmark"]
fastq_dir = get_result_dir(config) + "/fastq/"
bam_dir = get_result_dir(config) + "/bam/"
cnv_dir = get_result_dir(config) + "/cnv/"
cutadapt_dir = get_result_dir(config) + "/cutadapt/"
result_dir = get_result_dir(config) + "/"
qc_dir = get_result_dir(config) + "/qc/"
vcf_dir = get_result_dir(config) + "/vcf/"
vep_dir = get_result_dir(config) + "/vep/"

singularity_image = config['singularity']['image'] 

try:
    SENTIEON_LICENSE = os.environ["SENTIEON_LICENSE"]
    SENTIEON_INSTALL_DIR = os.environ["SENTIEON_INSTALL_DIR"]
except Exception as error:
    print("ERROR: Set Environment variable to run this pipeline.")
    raise

SENTIEON_DNASCOPE = rule_dir + 'assets/sentieon_models/SentieonDNAscopeModelBeta0.4a-201808.05.model'
SENTIEON_TNSCOPE = rule_dir + 'assets/sentieon_models/SentieonTNscopeModel_GiAB_HighAF_LowFP-201711.05.model'
os.environ["SENTIEON_TMPDIR"] = result_dir

# explictly check if cluster_config dict has zero keys.
if len(cluster_config.keys()) == 0:
    cluster_config = config

# rules for pipeline
quality_check = ["snakemake_rules/quality_control/fastp.rule", \
                 "snakemake_rules/sentieon/sentieon_qc_metrics.rule", \
                 "snakemake_rules/quality_control/picard_wgs.rule", \
                 "snakemake_rules/quality_control/multiqc.rule"]
preprocessing = ["snakemake_rules/sentieon/sentieon_alignment.rule"]

if config['analysis']['analysis_type'] == "paired":
    variant_calling = ["snakemake_rules/sentieon/sentieon_tn_varcall.rule", \
                       "snakemake_rules/sentieon/sentieon_germline.rule", \
                       "snakemake_rules/variant_calling/somatic_sv_tumor_normal.rule", \
                       "snakemake_rules/variant_calling/cnvkit_paired.rule"]
    somatic_caller = ['tnhaplotyper','tnsnv', 'tnscope', 'manta', 'cnvkit']
    germline_caller = ['dnascope']

else:
    variant_calling = ["snakemake_rules/sentieon/sentieon_t_varcall.rule", \
                       "snakemake_rules/sentieon/sentieon_germline.rule", \
                       "snakemake_rules/variant_calling/somatic_sv_tumor_only.rule", \
                       "snakemake_rules/variant_calling/cnvkit_single.rule"]
    somatic_caller = ['tnhaplotyper','tnsnv', 'tnscope', 'manta', 'cnvkit']
    germline_caller = ['dnascope']

annotation = ["snakemake_rules/annotation/vep.rule"]

pipeline = quality_check + preprocessing + variant_calling + annotation 


for rule in pipeline:
    include: os.path.join(rule_dir, rule)

var_class = ["somatic", "germline"]
var_type = ["CNV", "SNV", "SV"]

wildcard_dict = { "sample": list(config["samples"].keys()),
                  "case_name": config["analysis"]["case_id"],
                  "var_type": var_type,
                  "var_class": var_class,
                  "var_caller": somatic_caller,
                  "bedchrom": config["panel"]["chrom"] if "panel" in config else [], 
                  "allow_missing": True
                }

if 'delivery' in config:
    def get_rule_output(rule_names=[]):
        '''
        Returns a all outputs that exists for rule_names
        set of (file_name, rule_name, wild_card) tuple
        '''
        output_files = list()
        output_files.append(('output_file', 'rulename', 'wildcard_value'))
        if not rule_names:
            rule_names = vars(rules).keys()
        for my_rule in rule_names:
            for my_file in getattr(rules, my_rule).output:
                for file_wildcard_list in snakemake.utils.listfiles(my_file):
                    output_files.append((file_wildcard_list[0], my_rule, list(file_wildcard_list[1])))
        
        return output_files
                        
    def get_rule_output_raw(rule_names=[], output_file_wildcards={}):
        '''Returns set of tuples for (rule, output, "") for all possible outputs'''
        output_files_raw = list()
        output_files_raw.append(('output_file', 'rulename', 'wildcard_name'))
        wildcard_sets = set()
        if not rule_names:
            rule_names = vars(rules).keys()
        for my_rule in vars(rules).keys():
            if my_rule in rule_names:
                for my_file in getattr(rules, my_rule).output:
                    pattern = re.compile(r"{([^}\.[!:]+)")
                    wildcard_subset = dict()
                    if pattern.findall(my_file):

                        wildcard_sets.update(pattern.findall(my_file))
                        for w in pattern.findall(my_file):
                            wildcard_subset[w] = output_file_wildcards[w]

                        for my_file_expanded in snakemake.io.expand(my_file,**output_file_wildcards):
                            output_files_raw.append((my_file_expanded, my_rule, list(wildcard_subset.keys())))
                    else:
                        output_files_raw.append((my_file, my_rule, [])) 
        return output_files_raw


    rules_to_deliver = {'qc':['multiqc', 'fastp'],
                        'alignment': ['bwa_mem', 'MarkDuplicates'],
                        'variant_call_tn': ['vardict_merge', 'mutect_merge', 'strelka', 'manta', 'sentieon_TNhaplotyper'],
                        'variant_call_t': ['vardict_merge', 'mutect_merge', 'manta'],
                        'annotation': ['vep_somatic']}
    
    output_files_ready = get_rule_output()
    output_files_ready = [dict(zip(output_files_ready[0], value)) for value in output_files_ready[1:]]
    delivery_ready = os.path.join(get_result_dir(config), "delivery_report", config["analysis"]["case_id"] + "_delivery_ready.hk" )
    write_json(output_files_ready, delivery_ready)
    FormatFile(delivery_ready) 

    output_files_raw = get_rule_output_raw(output_file_wildcards = wildcard_dict)
    output_files_raw = [dict(zip(output_files_raw[0], value)) for value in output_files_raw[1:]]

    delivery_raw = os.path.join(get_result_dir(config), "delivery_report", config["analysis"]["case_id"] + "_delivery_raw.hk" )
    write_json(output_files_raw, delivery_raw)
    FormatFile(delivery_raw) 

rule all:
    input:
        expand(bam_dir + "{sample}.bam", sample=config["samples"]),
        expand(bam_dir + "{sample}.dedup.bam", sample=config["samples"]),
        expand(bam_dir + "{sample}.dedup.realign.bam", sample=config["samples"]),
        expand(bam_dir + "{sample}.dedup.realign.recal_data.table", sample=config["samples"]),
        expand(bam_dir + "{sample}.dedup.realign.recal.csv", sample=config["samples"]),
        expand(bam_dir + "{sample}.dedup.realign.recal.pdf", sample=config["samples"]),
        expand(vep_dir + "{vcf}.vcf.gz", vcf = get_vcf(config, somatic_caller, [config["analysis"]["case_id"]])),
        expand(vcf_dir + "{vcf}.vcf.gz", vcf = get_vcf(config, germline_caller, config["samples"])),
        expand(qc_dir + "{sample}_sentieon_wgs_metrics.txt", sample=config["samples"]),
        expand(qc_dir + "{sample}_coverage", sample=config["samples"]),
        expand(qc_dir + "multiqc_report.html"),
    output:
        os.path.join(get_result_dir(config), "analysis_finish")
    shell:
        "date +'%Y-%m-%d T%T %:z' > {output}"

