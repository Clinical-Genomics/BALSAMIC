# vim: syntax=python tabstop=4 expandtab
# coding: utf-8

import os
import logging
import yaml
import sys

from collections import defaultdict
from colorclass import Color
from yapf.yapflib.yapf_api import FormatFile

from BALSAMIC.utils.cli import write_json
from BALSAMIC.utils.rule import get_chrom
from BALSAMIC.utils.rule import get_result_dir
from BALSAMIC.utils.rule import get_vcf
from BALSAMIC import __version__ as bv

shell.prefix("set -eo pipefail; ")

LOG = logging.getLogger(__name__)

rule_dir = config["rule_directory"]
benchmark_dir = config["analysis"]["benchmark"]
fastq_dir = get_result_dir(config) + "/fastq/"
bam_dir = get_result_dir(config) + "/bam/"
cnv_dir = get_result_dir(config) + "/cnv/"
cutadapt_dir = get_result_dir(config) + "/cutadapt/"
fastqc_dir = get_result_dir(config) + "/fastqc/"
result_dir = get_result_dir(config) + "/"
vcf_dir = get_result_dir(config) + "/vcf/"
vep_dir = get_result_dir(config) + "/vep/"
delivery_dir = get_result_dir(config) + "/delivery/"

singularity_image = config['singularity']['image'] 

# Declare sentieon variables 
sentieon = True
SENTIEON_LICENSE = ''
SENTIEON_INSTALL_DIR = ''

# explictly check if cluster_config dict has zero keys.
if len(cluster_config.keys()) == 0:
    cluster_config = config

try:
    SENTIEON_LICENSE = os.environ["SENTIEON_LICENSE"]
    SENTIEON_INSTALL_DIR = os.environ["SENTIEON_INSTALL_DIR"]
except Exception as error:
    sentieon = False
    LOG.warn("Set environment variables SENTIEON_LICENSE and SENTIEON_INSTALL_DIR to run SENTIEON variant callers")
    

# Define set of rules
qc_rules = [
  "snakemake_rules/quality_control/fastp.rule",
  "snakemake_rules/quality_control/fastqc.rule",
  "snakemake_rules/quality_control/GATK.rule",
  "snakemake_rules/quality_control/multiqc.rule",
  "snakemake_rules/quality_control/picard.rule",
  "snakemake_rules/quality_control/sambamba_depth.rule"
  ]

align_rules = [
  "snakemake_rules/align/bwa_mem.rule",
  "snakemake_rules/align/samtools.rule"
  ]

annotation_rules = [
  "snakemake_rules/annotation/vep.rule"
  ]

variantcalling_rules = [
  "snakemake_rules/variant_calling/germline.rule",
  "snakemake_rules/variant_calling/split_bed.rule"
  ]

germline_caller = ["haplotypecaller", "strelka_germline", "manta_germline"]

if sentieon:
    germline_caller.append('dnascope')

if config['analysis']['analysis_type'] == "paired":

    qc_rules.append("snakemake_rules/quality_control/contest.rule")

    variantcalling_rules.extend([
      "snakemake_rules/variant_calling/somatic_tumor_normal.rule",
      "snakemake_rules/variant_calling/somatic_sv_tumor_normal.rule",
      "snakemake_rules/variant_calling/mergetype.rule",
      "snakemake_rules/variant_calling/cnvkit_paired.rule"
      ])

    somatic_caller_snv = ["mutect", "vardict", "strelka"]
    sentieon_callers = ["tnhaplotyper"] if sentieon else [];
    somatic_caller_sv = ["manta", "cnvkit"]
    vcf_merge = ["vcfmerge"]
    
else:

    variantcalling_rules.extend([
      "snakemake_rules/variant_calling/cnvkit_single.rule",
      "snakemake_rules/variant_calling/mergetype_tumor.rule",
      "snakemake_rules/variant_calling/somatic_tumor_only.rule",
      "snakemake_rules/variant_calling/somatic_sv_tumor_only.rule"
      ])

    somatic_caller_snv = ["mutect", "vardict"]
    sentieon_callers = ["tnhaplotyper"] if sentieon else [];
    somatic_caller_sv = ["manta", "cnvkit"]
    vcf_merge = ["vcfmerge"]
      

#somatic_caller = somatic_caller_snv + somatic_caller_sv + vcf_merge + sentieon_callers
somatic_caller = somatic_caller_snv + somatic_caller_sv + sentieon_callers

config["rules"] = align_rules + qc_rules + variantcalling_rules + annotation_rules

for r in config["rules"]:
    include: os.path.join(rule_dir + r)

var_class = ["somatic", "germline"]
var_type = ["CNV", "SNV", "SV"]

wildcard_dict = { "sample": list(config["samples"].keys()),
                  "case_name": config["analysis"]["case_id"],
                  "var_type": var_type,
                  "var_class": var_class,
                  "var_caller": somatic_caller,
                  "bedchrom": config["panel"]["chrom"] if "panel" in config else [], 
                  "allow_missing": True
                }

if 'delivery' in config:
    def get_rule_output(rule_names=[]):
        '''
        Returns a all outputs that exists for rule_names
        set of (file_name, rule_name, wild_card) tuple
        '''
        output_files = list()
        output_files.append(('output_file', 'rulename', 'wildcard_value'))
        if not rule_names:
            rule_names = vars(rules).keys()
        for my_rule in rule_names:
            for my_file in getattr(rules, my_rule).output:
                for file_wildcard_list in snakemake.utils.listfiles(my_file):
                    output_files.append((file_wildcard_list[0], my_rule, list(file_wildcard_list[1])))
        
        return output_files
                        
        
    def get_rule_output_raw(rule_names=[], output_file_wildcards={}):
        '''Returns set of tuples for (rule, output, "") for all possible outputs'''
        output_files_raw = list()
        output_files_raw.append(('output_file', 'rulename', 'wildcard_name'))
        wildcard_sets = set()
        if not rule_names:
            rule_names = vars(rules).keys()
        for my_rule in vars(rules).keys():
            if my_rule in rule_names:
                for my_file in getattr(rules, my_rule).output:
                    pattern = re.compile(r"{([^}\.[!:]+)")
                    wildcard_subset = dict()
                    if pattern.findall(my_file):

                        wildcard_sets.update(pattern.findall(my_file))
                        for w in pattern.findall(my_file):
                            wildcard_subset[w] = output_file_wildcards[w]

                        for my_file_expanded in snakemake.io.expand(my_file,**output_file_wildcards):
                            output_files_raw.append((my_file_expanded, my_rule, list(wildcard_subset.keys())))
                    else:
                        output_files_raw.append((my_file, my_rule, [])) 
        return output_files_raw


    rules_to_deliver = {'qc':['multiqc', 'fastp'],
                        'alignment': ['bwa_mem', 'MarkDuplicates'],
                        'variant_call_tn': ['vardict_merge', 'mutect_merge', 'strelka', 'manta', 'sentieon_TNhaplotyper'],
                        'variant_call_t': ['vardict_merge', 'mutect_merge', 'manta'],
                        'annotation': ['vep_somatic']}
    
    output_files_ready = get_rule_output()
    output_files_ready = [dict(zip(output_files_ready[0], value)) for value in output_files_ready[1:]]
    delivery_ready = os.path.join(get_result_dir(config), "delivery_report", config["analysis"]["case_id"] + "_delivery_ready.hk" )
    write_json(output_files_ready, delivery_ready)
    FormatFile(delivery_ready) 

    output_files_raw = get_rule_output_raw(output_file_wildcards = wildcard_dict)
    output_files_raw = [dict(zip(output_files_raw[0], value)) for value in output_files_raw[1:]]

    delivery_raw = os.path.join(get_result_dir(config), "delivery_report", config["analysis"]["case_id"] + "_delivery_raw.hk" )
    write_json(output_files_raw, delivery_raw)
    FormatFile(delivery_raw) 

 
            
rule all:
    input:
        result_dir + "qc/" + "multiqc_report.html",
        expand(vep_dir + "{vcf}.vcf.gz", vcf=get_vcf(config, somatic_caller, [config["analysis"]["case_id"]])),
        expand(vep_dir + "{vcf}.pass.balsamic_stat", vcf=get_vcf(config, ["vardict"], [config["analysis"]["case_id"]])),
    output:
        os.path.join(get_result_dir(config), "analysis_finish")
    shell:
        "date +'%Y-%m-%d T%T %:z' > {output}"
